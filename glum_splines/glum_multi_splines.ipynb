{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Fitting Multiple Spline Terms in Python using glum\"\n",
        "format: md\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In my last post I covered how you can fit Penalized Splines using the `glum` library in Python. Notionally `glum` was built to fit Generalized Linear Models. However it was designed to give the user the option to pass in a custom penalty matrix. We took advantage of this capability to penalize a sequence of Basis Splines and also fit Cyclic splines which allow the user to model a symmetric effect. In this post I'd like to cover how we can use this method to fit multiple spline terms. My end goal would be to develop a framework to actually incorporate into the `glum` library, but that will be in a later post. \n",
        "\n",
        "#### The Data\n",
        "\n",
        "Since we will be including multiple terms it will probably be helpful to actually go over the data we are using. I am using a dataset that contains the hourly solar power generation in the state of Texas for 2022. [ERCOT](https://www.ercot.com/mp/data-products/data-product-details?id=PG7-126-M) puts a ton of data on their website so if you are ever in need of an open dataset and want to use some renewable energy data you should definitely explore their data portal. \n",
        "\n",
        "We will be building a simple model just to show off how we can fit multiple terms. Our model will predict the hourly solar power generation as a function of the hour of the day and the day of the year. I will also include a linear term for the total amount of solar installed that is available to help the model pick up an increase in installed solar throughout the year. \n",
        "$power \\sim BS(HourOfDay) + BS(DayOfYear) + TotalSolar$\n",
        "This is probably a really bad model of how solar power actually works :) but my only goal here is to build a framework for fitting multiple spline terms using `glum`, not solve the world's energy crisis. Our column of interest is the `ERCOT.PVGR.GEN` which shows the total MWs of solar generated in that hour but I'm going to make a more convenient `power_gw` field for use in this script. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from plotnine import *\n",
        "\n",
        "from sklearn.preprocessing import SplineTransformer\n",
        "from glum import GeneralizedLinearRegressor, GeneralizedLinearRegressorCV\n",
        "\n",
        "## Source: https://www.ercot.com/mp/data-products/data-product-details?id=PG7-126-M\n",
        "DATA_FILE = '../../data/ERCOT_2022_Hourly_Solar_Output.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: False\n",
        "\n",
        "retro_palette = np.array(\n",
        "    ['#D73F27', '#E8713D', '#EAA86C', '#F2DDB3',\n",
        "    '#81A9A0', '#2A8B99', '#1E6E8D', '#142B54']\n",
        ")\n",
        "\n",
        "def retro_palette_scaled(n = 1): \n",
        "    if n == 1:\n",
        "        scaled_palette = retro_palette[0]\n",
        "    if n >= 8:\n",
        "        scaled_palette = retro_palette\n",
        "    else:\n",
        "        pos = np.round(np.linspace(0, 7, n, endpoint=True)).astype('int')\n",
        "        scaled_palette = retro_palette[pos]\n",
        "    \n",
        "    return scaled_palette\n",
        "\n",
        "def theme_custom(*args, **kwargs):\n",
        "    custom_theme_args = dict(\n",
        "        dpi = 150, \n",
        "        figure_size = (5, 3), \n",
        "        plot_background=element_rect(fill = 'lightgrey'), panel_background=element_rect(fill = 'lightgrey'))   \n",
        "    \n",
        "    theme_args = {**custom_theme_args, **kwargs}\n",
        "    \n",
        "    return theme(**theme_args)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: False\n",
        "#| output: False\n",
        "solar_df = pd.read_csv(DATA_FILE)\n",
        "solar_df['time'] = pd.to_datetime(solar_df['Time (Hour-Ending)'])\n",
        "solar_df['hour'] = solar_df['time'].dt.hour\n",
        "solar_df['day'] = solar_df['time'].dt.dayofyear\n",
        "solar_df['week'] = solar_df['time'].dt.weekofyear\n",
        "solar_df['day_of_week'] = solar_df['time'].dt.day_of_week\n",
        "# daily_solar_df = solar_df.groupby('day')['ERCOT.PVGR.GEN'].agg('sum').reset_index()\n",
        "# daily_solar_df['power_gw'] = daily_solar_df['ERCOT.PVGR.GEN'] / 1000\n",
        "# ## n_knots = 26 so there is a knot every other week :shrug:\n",
        "# daily_solar_spline = SplineTransformer(n_knots = 26, include_bias = True).fit_transform(daily_solar_df[['day']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "solar_df['power_gw'] = solar_df['ERCOT.PVGR.GEN'] / 1000\n",
        "solar_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Building a spline \n",
        "\n",
        "Just like before we need to build our spline terms for each feature using the `SplineTransformer` function from the `scikit-learn.preprocessing` module. Then for each spline we need to build a 2nd order difference penalty matrix. I'm sure there is a better way to do this but I'm just going to keep track of everything in a dictionary for each term. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## n_knots = 26 so there is a knot every other week :shrug:\n",
        "spline_info = dict(daily = dict(), hourly = dict())\n",
        "spline_info['daily'] = dict(bsplines = SplineTransformer(n_knots = 26).fit_transform(solar_df[['day']]))\n",
        "spline_info['hourly'] = dict(bsplines = SplineTransformer(n_knots = 12).fit_transform(solar_df[['hour']]))\n",
        "for k,v in spline_info.items():\n",
        "    spline_info[k]['num_splines'] = v['bsplines'].shape[1]\n",
        "\n",
        "for k in spline_info.keys():\n",
        "    print(f'Number of Basis Splines for {k} feature: {spline_info[k][\"num_splines\"]}')\n",
        "\n",
        "for k, v in spline_info.items():\n",
        "    spline_info[k]['diff_matr'] = np.diff(np.eye(v['num_splines']), n = 2, axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next is our combined penalty matrix. When we had one spline term we could just pass in the inner transpose product of the difference matrix (I'm not sure if that's the correct term, but the $D^TD$ matrix is what I'm referring to). Now we have two spline terms and a simple linear term. Since each spline term has its own penalty we can structure the full penalty matrix as a \"sequence\" of individual penalty matrices. So the difference matrices will be on the (large) diagonal and the outer triangles are filled with zeros. This way each penalty only interacts with its own corresponding spline coefficients and no other term's coefficients. \n",
        "\n",
        "$$\\displaylines{ \\mathbf{D_{hourly}} = \\text{Hourly Penalty Matrix}\\\\\n",
        "\\mathbf{D_{daily}} = \\text{Daily Penalty Matrix} \\\\\n",
        "\\mathbf{D_{model}} = \n",
        "\\begin{bmatrix}\n",
        "\\mathbf{D_hourly} & \\mathbf{0} \\\\\n",
        "\\mathbf{0} & \\mathbf{D_{daily}}\n",
        "\n",
        "\\end{bmatrix}\n",
        "}\n",
        "$$\n",
        "\n",
        "This allows us to combine any number of individual terms. More terms will obviously increase the time it takes to fit each model. I would love to test this further but my hunch is that it actually won't slow down a model fit too much. The reason is that both the model matrix containing the spline values and the penalty matrix will be \"mostly sparse\". What I mean by that is that they aren't completely diagonal matrices, but most sections of the matrix are only non-zero near the diagonal. The `glum` library was designed to handle sparse and nearly-sparse matrices more efficiently than other libraries. I'm hoping that these improvements will flow through to fitting GAMs, but we will have to test that on a later date. \n",
        "\n",
        "In thinking through how to do this in code I believe the best option is to accept a list of penalty matrices. Then iteratively fill in a matrix of zeros that is the full size of the combined penalties. This also allows us to include non-spline terms by including a 2d matrix of shape (1, 1) that will penalize the size of the linear coefficient. In my research I found that there is actually a `np.block` function, but it would force me to compute the zero matrices in the uppper and lower triangles first to then manually create the block matrix. That seems more complicated than filling in a square matrix with the penalty matrices instead. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def build_multiterm_penalty(penalty_matr_list):\n",
        "    ## Need to use the column shapes because the difference matrix removes rows\n",
        "    num_features_list = list(map(lambda x: x.shape[1], penalty_matr_list))\n",
        "    num_features = sum(num_features_list)\n",
        "    ## Pre-create the matrix for efficient memory allocation\n",
        "    penalty_matrix = np.zeros(shape = [num_features, num_features])\n",
        "    current_row = 0\n",
        "    for m in penalty_matr_list:\n",
        "        size = m.shape[1]\n",
        "        end_row = current_row + size\n",
        "        m_square = np.dot(m.T, m)\n",
        "        penalty_matrix[current_row:end_row, current_row:end_row] = m_square\n",
        "        current_row = end_row\n",
        "\n",
        "    return penalty_matrix\n",
        "## simple test\n",
        "build_multiterm_penalty([np.eye(2) * 2, np.eye(1) * 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So this will give us our combined penalty matrix. Now lets calculate our real one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "full_penalty_list = [np.eye(1), \n",
        "                     spline_info['hourly']['diff_matr'],\n",
        "                     spline_info['daily']['diff_matr']]\n",
        "gam_penalty = build_multiterm_penalty(full_penalty_list)\n",
        "print(gam_penalty.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our model matrix is a lot easier; we can simply stack the spline values we got from our transformer together. Here you can see the first feature values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## build model matrix\n",
        "model_matrix = np.hstack([\n",
        "    solar_df[['Total Solar Installed, MW']], \n",
        "    spline_info['hourly']['bsplines'],\n",
        "    spline_info['daily']['bsplines']\n",
        "    ])\n",
        "print(model_matrix.shape)\n",
        "np.round(model_matrix[:3, :10], 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fitting the Model\n",
        "\n",
        "Now that we have our penalty matrix and model matrix all that we have left to do is actually fit the model. We can visualize our first day's worth of predictions to see how the model does. While this doesn't technically show only the effect of the hourly coefficients we can basically interpret it as such anyway; both the day-of-the-year spline and the linear solar capacity terms will add a fixed amount to each day. So any within-day differences are due only to the hourly smoothing spline. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gam_model = GeneralizedLinearRegressor(P2 = gam_penalty, alpha = 1, fit_intercept = False).fit(X = model_matrix, y = solar_df['power_gw'])\n",
        "solar_df['preds_baseline'] = gam_model.predict(model_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: False\n",
        "(ggplot(solar_df.query('day <= 1'), aes(x = 'hour')) + \n",
        "    geom_line(aes(y = 'preds_baseline'), color = 'blue', size = 1.5) +\n",
        "    geom_point(aes(y = 'power_gw'), alpha = .5) +\n",
        "    xlab('Hour of the Day') + ylab('Predicted (Blue Line) vs Actual Solar Power') + ggtitle('Model Predictions for Jan 1') +\n",
        "    scale_y_continuous(limits = (-2, 5)) +\n",
        "    theme_bw() + theme_custom()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: False\n",
        "#| eval: False\n",
        "gam_model.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model certainly picks up on the general trend of solar power generation rising during the day before falling in the evening. There are *many* reasons why this does a poor job of actually modeling whats going on in the real world. One example is that the hourly term is fixed throughout the year, so the model can't pick up on the fact that summer days are longer than days in the winter. In addition the model seems to be predicting negative numbers for some hours which doesn't make any sense in the real world. All of those could be fixed with more realistic modeling choices. One thing we can fix with just our spline penalties is the fact that moving from midnight to 1am there is a discontinuity, but in actuality the predictions should basically be the same. We did this in our last post using a cyclic penalty where we penalize the difference between the first and last coefficient. We aren't going to do anything different here, but I just want to show how easy it is even with multiple spline terms. We just replace the prior difference matrix with the new cyclic difference matrix and the additional penalty will be picked up automatically when we create our `m_squared` matrix in the `build_multiterm_penalty` function. The only thing that may be different in this code is I'm going to multiply the new cyclic penalty matrix by an additional penalty term so that the model is forced to respect this new constraint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def add_cyc_penalty(diff_matr):\n",
        "    num_rows, num_cols = diff_matr.shape\n",
        "    ## create an empty row\n",
        "    cyc_row = np.zeros(num_cols)\n",
        "    ## \\beta @ diff_matr will penalize (\\beta_{0} - \\beta_{-1})\n",
        "    cyc_row[0] = 1\n",
        "    cyc_row[-1] = -1\n",
        "    ## add the cyclic penalty row to the penalty matrix\n",
        "    diff_matr_cyc = np.vstack([diff_matr, cyc_row])\n",
        "    return diff_matr_cyc\n",
        "\n",
        "cyclic_penalty = np.sqrt(3.5)\n",
        "hourly_penalty_cyc = add_cyc_penalty(spline_info['hourly']['diff_matr'])\n",
        "hourly_penalty_cyc = hourly_penalty_cyc * cyclic_penalty\n",
        "\n",
        "full_penalty_list_cyc = [np.eye(1), \n",
        "                     hourly_penalty_cyc,\n",
        "                     spline_info['daily']['diff_matr']]\n",
        "gam_penalty_cyc = build_multiterm_penalty(full_penalty_list_cyc)\n",
        "\n",
        "gam_model_cyc = GeneralizedLinearRegressor(P2 = gam_penalty_cyc, alpha = 1, fit_intercept = False).fit(X = model_matrix, y = solar_df['power_gw'])\n",
        "solar_df['preds_cyc'] = gam_model_cyc.predict(model_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: False\n",
        "model_labels = {'preds_cyc': 'Cyclic', 'preds_baseline': 'Baseline'}\n",
        "\n",
        "plot_cyc_df = (\n",
        "    solar_df.\n",
        "    query('day <= 1').\n",
        "    melt(id_vars = ['hour'], value_vars = ['preds_cyc', 'preds_baseline'],\n",
        "         var_name = 'model', value_name = 'preds').\n",
        "    assign(model_label = lambda df: [model_labels[v] for v in df['model']])\n",
        ")\n",
        "\n",
        "ggplot(plot_cyc_df, aes(x = 'hour', y = 'preds')) + \\\n",
        "    geom_line(aes(color = 'model_label'), size = 2) +\\\n",
        "    geom_point(solar_df.query('day <= 1'), aes(y = 'power_gw'), alpha = .5) +\\\n",
        "    scale_y_continuous(limits = (-2, 5)) +\\\n",
        "    scale_x_continuous(breaks = (0, 6, 12, 18)) +\\\n",
        "    xlab('Hour of the Day') + ylab('Predicted vs Actual Solar Power') + ggtitle('Model Predictions Comparison for Jan 1') +\\\n",
        "    annotate('text', label = 'Cyclic', color = retro_palette[-1], x = 2, y = 1, size = 12) +\\\n",
        "    annotate('text', label = 'Baseline', color = retro_palette[0], x = 6, y = -1, size = 12) +\\\n",
        "    guides(color = False) +\\\n",
        "    scale_color_manual(values = retro_palette_scaled(n = 2)) +\\\n",
        "    theme_bw() + theme_custom()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see our hourly coefficients are more symmetric, but also much more muted than the baseline model; the baseline `gam_model` predicts a max solar output of ~4.1GW while the cyclic `gam_model_cyc` only predicts a value of ~3.2. The reason for this is that when we multiplied our cyclic penalty matrix (`hourly_penalty_cyc`) by an additional penalty value (`cyclic_penalty`) we increased the weight on the cyclic penalty but also increased the weight on the original difference penalty. This makes it harder for the model to justify consecutive spline coefficients with large differences, which makes the overall curve less, well, curvy. We can fix this by rewriting our `add_cyc_penalty` function to take the additional penalty value as an input and multiplying only the row that corresponds to the cyclic penalty (the last row) by our penalty value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def add_cyc_penalty(diff_matr, penalty = 1):\n",
        "    num_rows, num_cols = diff_matr.shape\n",
        "    ## create an empty row\n",
        "    cyc_row = np.zeros(num_cols)\n",
        "    ## \\beta @ diff_matr will penalize (\\beta_{0} - \\beta_{-1})\n",
        "    cyc_row[0] = 1\n",
        "    cyc_row[-1] = -1\n",
        "    ## add the cyclic penalty row to the penalty matrix\n",
        "    cyc_row = cyc_row * penalty\n",
        "    diff_matr_cyc = np.vstack([diff_matr, cyc_row])\n",
        "    return diff_matr_cyc\n",
        "\n",
        "cyclic_penalty = np.sqrt(10)\n",
        "## Now our cyclic_penalty is an input instead of an additional step\n",
        "hourly_penalty_cyc = add_cyc_penalty(spline_info['hourly']['diff_matr'], cyclic_penalty)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: False\n",
        "full_penalty_list_cyc = [np.eye(1), \n",
        "                     hourly_penalty_cyc,\n",
        "                     spline_info['daily']['diff_matr']]\n",
        "gam_penalty_cyc = build_multiterm_penalty(full_penalty_list_cyc)\n",
        "\n",
        "gam_model_cyc = GeneralizedLinearRegressor(P2 = gam_penalty_cyc, alpha = 1, fit_intercept = False).fit(X = model_matrix, y = solar_df['power_gw'])\n",
        "solar_df['preds_cyc_pen'] = gam_model_cyc.predict(model_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: False\n",
        "model_labels['preds_cyc_pen'] = 'Cyclic Penalty'\n",
        "\n",
        "plot_cyc_df2 = (\n",
        "    solar_df.\n",
        "    query('day <= 1').\n",
        "    melt(id_vars = ['hour'], \n",
        "         value_vars = ['preds_cyc', 'preds_baseline', 'preds_cyc_pen'],\n",
        "         var_name = 'model', value_name = 'preds').\n",
        "    assign(model_label = lambda df: [model_labels[v] for v in df['model']])\n",
        ")\n",
        "\n",
        "ggplot(plot_cyc_df2, aes(x = 'hour', y = 'preds')) + \\\n",
        "    geom_line(aes(color = 'model_label'), size = 2) +\\\n",
        "    geom_point(solar_df.query('day <= 1'), aes(y = 'power_gw'), alpha = .5) +\\\n",
        "    scale_y_continuous(limits = (-2, 5)) +\\\n",
        "    scale_x_continuous(breaks = (0, 6, 12, 18)) +\\\n",
        "    xlab('Hour of the Day') + ylab('Predicted vs Actual Solar Power') + ggtitle('Model Predictions Comparison for Jan 1') +\\\n",
        "    annotate('text', label = 'Cyclic', color = retro_palette[-1], x = 2, y = 1, size = 12) +\\\n",
        "    annotate('text', label = 'Baseline', color = retro_palette[0], x = 6, y = -1, size = 12) +\\\n",
        "    annotate('text', label = 'Cyclic Penalty', color = retro_palette[4], x = 18, y = -0.75, size = 12) +\\\n",
        "    scale_color_manual(values = retro_palette_scaled(n = 3)[[0, 2, 1]]) +\\\n",
        "    guides(color = False) +\\\n",
        "    theme_bw() + theme_custom()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is still some discontinuity between 11pm and midnight, but our predictions have maintained their more accurate predictions during the middle of the day while shrinking the gap. In fact, I can't seem to figure out how to close this gap. If I increase the penalty value in the updated `add_cyclic_penalty` function the coefficients really don't change. If I make it too large then `glum` will throw errors about how the `P2` matrix must be positive semi-definite. I will have to look into this but wanted to wrap this post up regardless since the core idea was just including multiple splines, which we have done. \n",
        "\n",
        "From here I would love to actually look at the internals in the `glum` library to see if its feasible to implement this capability directly into the library. For now hopefully this explains a little more about P-splines and fitting models with `glum`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: False\n",
        "#| eval: False\n",
        "def between(x, lb, ub, ge = True, le = True):\n",
        "    if ge:\n",
        "        lower = np.where(x >= lb, True, False)\n",
        "    else:\n",
        "        lower = np.where(x > lb, True, False)\n",
        "    \n",
        "    if le:\n",
        "        upper = np.where(x <= ub, True, False)\n",
        "    else:\n",
        "        upper = np.where(x < ub, True, False)\n",
        "\n",
        "    return lower & upper\n",
        "\n",
        "days = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday',\n",
        "        5: 'Weekend', 6: 'Weekend'}\n",
        "turkey_df = solar_df.query('(week >= 45) & (week <= 49)').assign(week = lambda df: df['week'].astype('str'))\n",
        "turkey_df['Week'] = np.where(between(turkey_df['week'].astype('int'), 47, 47), 'Thanksgiving', 'Baseline')\n",
        "turkey_df['weekday'] = pd.Categorical([days[i] for i in turkey_df['day_of_week']], categories = list(days.values())[:-1], ordered = True)\n",
        "turkey_df_avg = turkey_df.groupby(['Week', 'hour', 'weekday'])['ERCOT.LOAD'].mean().reset_index()\n",
        "turkey_df_avg['Total Load (GW)'] = turkey_df_avg['ERCOT.LOAD'] / 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: False\n",
        "#| eval: False\n",
        "(ggplot(turkey_df_avg, aes(x = 'hour', y = 'Total Load (GW)')) + \n",
        "    geom_line(aes(color = 'Week'), size = 2) + \n",
        "    facet_wrap('~weekday', nrow = 2) + \n",
        "    scale_x_continuous(breaks = [8, 12, 16, 20], name = 'Hour') +\n",
        "    ggtitle('Thanksgiving Power Demand in Texas (2022)') +\n",
        "    scale_color_manual(values = ['white', '#511f16']) + \n",
        "    labs(color = '') +\n",
        "    theme(plot_background = element_rect(fill = '#B6562A'), \n",
        "          strip_background = element_rect(fill = '#9c2f2f'),\n",
        "          strip_text = element_text(color = '#dbba33', face = 'bold'),\n",
        "          panel_background = element_rect(fill = '#B6562A'),\n",
        "          legend_background = element_rect(fill = '#B6562A'),\n",
        "          legend_key = element_rect(fill = '#B6562A'),\n",
        "          panel_grid_minor = element_blank(),\n",
        "          panel_grid_major = element_line(color = 'grey'),\n",
        "          legend_position = 'bottom', dpi = 300, figure_size=(6, 3))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: False\n",
        "#| eval: False\n",
        "B11, B12, B13\n",
        "B21, B22, B23\n",
        "B31, B32, B33\n",
        "\n",
        "B11, B21, B31\n",
        "B12, B22, B32\n",
        "B13, B23, B33\n",
        "\n",
        "# 2o1 + -o3, o2, -o1 + 2o3\n",
        "# (2o1o1 + -o3o1) + (o2o2) + (-o1o3 + 2o3o3)\n",
        "# 2o1^2 + o2^2 + 2o3^2 - 2o1o3\n",
        "# 2o1^2 + o2^2 + 2o3^2 - 2o1(o1 + x)\n",
        "# 2o1^2 + o2^2 + 2o3^2 - 2o1^2 + 2o1x\n",
        "# o2^2 + 2o3^2 + 2o1x"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}